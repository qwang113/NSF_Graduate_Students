---
title: "NSF Graduate Student Data Exploration"
author: "Qi Wang"
date: "2023-09-18"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(openxlsx)
library(dplyr)
library(tidyr)
library(nlme)
library(ggplot2)
library(maps)
library(gifski)
library(gganimate)
library(reshape2)
```

# Data introduction

In each file, there are three sheets, recording the race, support and postdoctoral. Each sheet contains a unique combination of year, school_id, and gss_code. These ID information are replicated in each sheet in each file, meaning that we are researching the same bunch of schools, the only difference is the variables. 

There is a version of 2017 called "2017old" since in 2017 they adjusted some criteria.Due to these changes, the 2017 data are not comparable to prior years. A set of bridge estimates was created to permit comparisons to previous years and for trend analyses.

To begin with, I will first go further into the first sheet of each file and make it as an example about data wrangling for further reference.

```{r}
get_data <- function(var_name_old, var_name_new, sheet){
  # Since there is a data collection method change in 2017, so var_name_old should be the previous variable name, and the var_name_new should be the name after 2017. There is a sheet recording the equivalent names for them.
  ID_variables <- c(
    "institution_id","school_id","UNITID","year", "Institution_Name","hdg_inst","toc_code", "institution_state", "hbcu_flag","land_grant_flag","carnegie_code_1994","carnegie_code_2005","carnegie_code_2010","carnegie_code_2015","full_school_name","school_name","school_zip","school_type_code","gss_code","hdg_code"
  )
  
  all_sheet<- vector("list")
  selected_mat <-  vector("list")
for (i in 1:50) {
  print( paste("Now retrieving data of year: ",i+1971))
    all_sheet[[i]] <- read.xlsx( paste("D:/77/UCSC/study/Research/temp/NSF_dat/NSF_grad/gss",1971+i,"_Code.xlsx", sep = ""), sheet = sheet)
    if(1971+i <= 2016){selected_mat[[i]] <- all_sheet[[i]][,c(ID_variables, var_name_old)]}
    else{selected_mat[[i]] <- all_sheet[[i]][,c(ID_variables, var_name_new)]}
}
  
# Add coordinates
  final_mat <- bind_rows(selected_mat)
  col_coords <- read.csv("D:/77/UCSC/study/Research/temp/NSF_dat/ins_loc.csv", header = TRUE)
  id_coords <- data.frame("UNITID" = as.character(col_coords$UNITID) , "long" = as.numeric(col_coords$LONGITUDE), "lat" = as.numeric(col_coords$LATITUDE))
  out <- left_join(final_mat, id_coords, by = "UNITID")
  
  NA_sch <- out$Institution_Name[which(is.na(out$long))]

  # for (i in 1:length(schools)) {
  #   out$long[which(out$Institution_Name==schools[i])] <- longitude[i]
  #   out$lat[which(out$Institution_Name==schools[i])] <- latitude[i]
  # }
  return(list("DAT" = out, "NAschools" = unique(NA_sch)))
}


dat <- get_data("ft_tot_all_races_v", "ft_tot_all_races_v", "Race")
# na.schools <- dat$NAschools
# coordinates <- data.frame(
#   School = c(
#     "George Peabody College for Teachers",
#     "Institute of Textile Technology",
#     "Medical College of Pennsylvania, The",
#     "US International University",
#     "Institute of Paper Science & Technology",
#     "Atlanta University",
#     "Medical College of Georgia",
#     "Woods Hole Oceanographic Institution",
#     "Univ of Med and Dentistry of New Jersey",
#     "Polytechnic University"
#   ),
#   Longitude = c(
#     -86.799152, -78.918341, -75.170725, -117.161087, -84.408927, -84.381822, -82.331129, -70.645207, -74.176053, -73.986827
#   ),
#   Latitude = c(
#     36.146895, 35.905047, 39.958812, 32.777416, 33.778813, 33.748995, 33.474349, 41.527565, 40.730610, 40.694185
#   )
# 
# )

# There are schools without UNITID, hard to merge, continue merging or omit them?
# What data should we finally use? Full recorded? All years?
# After 2017, more variables are added, how to handle those? Ignore?

# 1. find the complete data
# 2. fit some models. ts model, countts
# 3. one step ahead prediction mse for several years
## 4. add jitters to the plot
```

```{r}
use_dat <- dat$DAT[-which(dat$DAT$UNITID==999999),c("UNITID","Institution_Name", "year","gss_code","ft_tot_all_races_v","long","lat")]
tem = spBayes::pointsInPoly(as.matrix(map_data("usa", region = "main")[,1:2]),cbind(use_dat$long, use_dat$lat))
# summed_dat <- aggregate( ft_tot_all_races_v ~  school_id + gss_code + year, data = use_dat, FUN = function(x) sum(x, na.rm = TRUE))
use_dat <- use_dat[tem,]
sch_gss <- as.numeric(paste(as.character(use_dat$UNITID), as.character(use_dat$gss_code), sep = ""))
final_dat <- data.frame("ID" = sch_gss,"col_sch" = paste(use_dat$Institution_Name, use_dat$gss_code, sep = "_") ,"year" = as.numeric(use_dat$year), "y" = as.numeric(use_dat$ft_tot_all_races_v),
                        "long" = use_dat$long, "lat" = use_dat$lat)
# example_index <- sample(unique(final_dat$ID), 20, replace = FALSE)
# final_dat_ex <- final_dat[final_dat$ID %in% example_index, ]
```

Then I made a gif plot with instructions here:
https://conservancy.umn.edu/bitstream/handle/11299/220339/time-maps-tutorial-v2.html?sequence=3&isAllowed=y
```{r}
# ggplot(data = final_dat_ex, aes(x = year, y = y, group = ID, color = ID)) +
#   geom_line() +
#   labs(x = "year", y = "y", title = "Time Series Plot by School ID and GSS Code") +
#   theme_minimal() + 
#   scale_x_continuous(breaks = seq(from = 1972, to = 2021, by = 2)) + 
#   theme(legend.position = "none") +
#   theme(plot.title = element_text(hjust = 0.5))  
```
https://conservancy.umn.edu/bitstream/handle/11299/220339/time-maps-tutorial-v2.html?sequence=3&isAllowed=y

```{r}

# us_map <- map_data("state")
# gif_students <-
# ggplot() +
# geom_path(data = us_map, aes(x = long, y = lat, group = group), color = "red") +
# geom_point(data = final_dat, aes(x = long, y = lat, color = y, size = y, group = year)) + 
# scale_colour_gradientn(colours = hcl.colors(10), na.value = "red", limits = c(0, quantile(final_dat$y, 0.975))) +
# transition_time(year) +  
# labs(title = 'Year: {frame_time}') +
# coord_fixed(ratio = 1.1) + 
# theme(plot.title = element_text(hjust = 0.5))  +
# theme_void()
# 
# num_years <- diff(range(final_dat$year)) + 1
# 
# anim_save("example1.gif", animation = animate(gif_students, nframes = num_years, fps = 2, width = 1500, height = 900), path = here::here())

```
# Find the Complete Data

```{r}

all_schools <- unique(final_dat$ID)
stay <- rep(NA, length(all_schools))
for (i in 1:length(all_schools)) {
  stay[i] <- length( unique( final_dat$year[which(final_dat$ID==all_schools[i])] ) ) == 50 & 
    length( final_dat$year[which(final_dat$ID==all_schools[i])] ) == 50
}
stay_schools <- unique(final_dat$ID)[stay]
stay_dat <- final_dat[final_dat$ID %in% stay_schools, ]
write.csv(stay_dat, "D:/77/UCSC/study/Research/temp/NSF_dat/nsf_final.csv", row.names = FALSE)
```




